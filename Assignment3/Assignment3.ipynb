{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "# Processing & feature generation\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB # NOTE: You will require Python3 64-bit kernel to run GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Summary:\n",
    "### Yelp:\n",
    "        Training set: 7000\n",
    "        Valid set: 1000\n",
    "        Test set: 2000\n",
    "\n",
    "        Type: 5 class classification problem (1:worst - 5:best)\n",
    "\n",
    "### IMDB:\n",
    "        Training set: 15000\n",
    "        Valid set: 10000\n",
    "        Test set: 25000\n",
    "\n",
    "        Type: 2 class problem (1: positive, 0: negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "PATH = r'./Datasets'\n",
    "M_FEATURES = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized methods for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(filename, column_names=['Review', 'Label']):\n",
    "    '''\n",
    "    Parses the file into a pandas dataframe object.\n",
    "    :param filename: The file to be parsed\n",
    "    :param column_names: The desired column names of the dataframe\n",
    "    :return: The file as a dataframe object\n",
    "    '''\n",
    "    return pd.read_table(os.path.join(PATH, filename), sep='\\t', lineterminator='\\n', header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataframe, column):\n",
    "    '''\n",
    "    Preprocesses the reviews by stripping away all non-word, non-space characters. Additionally removes <br /> tags for IMDB set\n",
    "    :param dataframe: The dataframe object\n",
    "    :param column: The column to be preprocessed. This will be 'Review' for this assignment.\n",
    "    :return: None\n",
    "    '''\n",
    "    dataframe[column] = dataframe[column].str.replace('<br /><br />', ' ').str.replace('[^\\w\\s]', '').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(training_dict, column, features=M_FEATURES, save_to_file=False):\n",
    "    '''\n",
    "    For each training set in training_dict, return the corresponding vocabulary to be used as the feature set.\n",
    "    The method first counts the frequencies of all words across each training set, and then chooses the top most\n",
    "    frequent words as the feature set.\n",
    "    :param training_dict: The dictionary of training sets. We have yelp and IMDB training sets.\n",
    "    :param column: The column to get the words from. This is 'Review'\n",
    "    :param features: The number of top most frequent features to be used\n",
    "    :param save_to_file: If True, saves the feature set, along with the frequencies and IDs to their corresponding file\n",
    "                         as required by the assignment\n",
    "    :return: Dictionary of vocabularies for both yelp and IMDB\n",
    "    '''\n",
    "    most_common = {}\n",
    "    for dataset in training_dict:\n",
    "        all_words_list = [word for sentence in training_dict[dataset][column].str.split().tolist() for word in sentence]\n",
    "        top_k = Counter(all_words_list).most_common(features)\n",
    "        most_common[dataset] = {word[0]: i for i, word in enumerate(top_k)}\n",
    "\n",
    "        if save_to_file:\n",
    "            # Write to file for submission\n",
    "            vocab = pd.DataFrame(top_k)\n",
    "            vocab[2] = np.arange(0, features)  # These are the word IDs\n",
    "            vocab.to_csv('./Submission/' + dataset + '-vocab.txt', sep='\\t', header=False, index=False, columns=[0, 2, 1])\n",
    "\n",
    "    return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(datasets, vocabulary, xname='Review', yname='Label'):\n",
    "    '''\n",
    "    Converts each dataset in datasets to both binary and frequency bag of words representations.\n",
    "    :param datasets: Dictionary of datasets to be converted\n",
    "    :param vocabulary: The vocabulary extracted by :func:`get_vocabulary`\n",
    "    :param xname: The name of the feature column ('Review')\n",
    "    :param yname: The name of the label column ('Label')\n",
    "    :return: Binary and frequency BoW dictionaries. Each dictionary has keys corresponding to the keys of datasets.\n",
    "    '''\n",
    "    binary_bow = {}\n",
    "    freq_bow = {}\n",
    "    vectorizer = CountVectorizer(vocabulary=vocabulary)\n",
    "    for name in datasets:\n",
    "        vec = vectorizer.fit_transform(datasets[name][xname])\n",
    "        freq_bow[name] = [normalize(vec), datasets[name][yname]]\n",
    "        vec[vec > 1] = 1\n",
    "        binary_bow[name] = [vec, datasets[name][yname]]\n",
    "\n",
    "    return binary_bow, freq_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_converted_dataset(datasets, vocab_dict, dataset_name):\n",
    "    '''\n",
    "    Replaces the words of the datasets by their unique IDs from the vocabulary, as required by the assignment. It then\n",
    "    writes the converted datasets to file.\n",
    "    :param datasets: Dictionary containing the datasets to be converted\n",
    "    :param vocab_dict: The vocabulary dictionary obtained from :func:`get_vocabulary`\n",
    "    :param dataset_name: 'yelp' or 'imdb'\n",
    "    :return: None\n",
    "    '''\n",
    "    for dataset in datasets[dataset_name]:\n",
    "        with open('./Submission/' + dataset_name + '-' + dataset + '.txt', 'w') as file:\n",
    "            for i in range(len(datasets[dataset_name][dataset])):\n",
    "                file.write(' '.join([str(vocab_dict[dataset_name][word]) for word in datasets[dataset_name][dataset].iloc[i, 0].split()\n",
    "                                     if word in vocab_dict[dataset_name]]) + '\\t' + str(datasets[dataset_name][dataset].iloc[i, 1]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_classifier(train_on, predict_on):\n",
    "    '''\n",
    "    Classifies predict_on into a random class.\n",
    "    :param train_on: The training set\n",
    "    :param predict_on: The test set\n",
    "    :return: Predicted labels of the test set\n",
    "    '''\n",
    "    return np.random.choice(np.unique(train_on[1]), len(predict_on[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_class_classifier(train_on, predict_on):\n",
    "    '''\n",
    "    Classifies predict_on into the majority class (mode) of the training set.\n",
    "    :param train_on: The training set\n",
    "    :param predict_on: The test set\n",
    "    :return: Predicted labels of the test set\n",
    "    '''\n",
    "    return np.full(len(predict_on[1]), scipy.stats.mode(train_on[1])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_format(s, *args):\n",
    "    '''\n",
    "    Helper to print formatted strings\n",
    "    :param s: The unformatted string with placeholders\n",
    "    :param args: The args that go into the placeholders of s\n",
    "    :return: None\n",
    "    '''\n",
    "    print(s.format(*args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_clf_test(clf, dataset_dict, tune_params=None, tune=True, average='micro'):\n",
    "    '''\n",
    "    Fits the classifier clf to the training set, and predicts on the test set. Prints the F1 scores for each set.\n",
    "    :param clf: An sklearn classifier or :func:`random_classifier` or :func:`majority_class_classifier`\n",
    "    :param dataset_dict: Dictionary of datasets to predict on (must contain keys 'train', 'valid', 'test')\n",
    "    :param tune_params: If not None, will tune the parameters on the validation set before predicting on test. Tuning\n",
    "                        is done using sklearn's GridSearchCV\n",
    "    :param tune: Must be true in addition to tune_params not being None to perform tuning\n",
    "    :param average: The average paramters of sklearn's f1_score. Defaults to 'micro'\n",
    "    :return: None\n",
    "    '''\n",
    "    name = clf.__name__.upper() if callable(clf) else clf.__class__.__name__.upper()\n",
    "    print_format('\\tScores using {}:', name)\n",
    "\n",
    "    if not callable(clf):\n",
    "        train_x = dataset_dict['train'][0]\n",
    "        train_y = dataset_dict['train'][1]\n",
    "        if tune and tune_params is not None:\n",
    "            # Set up GridSearch with validation set\n",
    "            valid_x, valid_y = dataset_dict['valid'][0], dataset_dict['valid'][1]\n",
    "            ps = PredefinedSplit(test_fold=[-1 if i < len(train_y) else 0 for i in range(len(train_y) + len(valid_y))])\n",
    "            clf = GridSearchCV(clf, tune_params, cv=ps, n_jobs=2)\n",
    "            train_x = scipy.sparse.vstack([train_x, valid_x])\n",
    "            train_y = np.concatenate([train_y, valid_y])\n",
    "\n",
    "        clf.fit(train_x, train_y)\n",
    "        if tune and tune_params is not None: print('\\t\\tBest params:', clf.best_params_)\n",
    "\n",
    "    for dname, dset in dataset_dict.items():\n",
    "        score = f1_score(dset[1], clf(dataset_dict['train'], dset) if callable(clf) else clf.predict(dset[0]), average=average)\n",
    "        print_format('\\t\\t{}: {}', dname.upper(), score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful flags\n",
    "WRITE = True # If true, write to file\n",
    "PERFORM_TUNING = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the datasets using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yelp datsets\n",
    "yelp_train = read_dataset('yelp-train.txt')\n",
    "yelp_valid = read_dataset('yelp-valid.txt')\n",
    "yelp_test = read_dataset('yelp-test.txt')\n",
    "\n",
    "# IMDB datasets\n",
    "imdb_train = read_dataset('IMDB-train.txt')\n",
    "imdb_valid = read_dataset('IMDB-valid.txt')\n",
    "imdb_test = read_dataset('IMDB-test.txt')\n",
    "\n",
    "# All sets\n",
    "datasets = {\n",
    "    'yelp': {'train': yelp_train, 'valid': yelp_valid, 'test': yelp_test},\n",
    "    'imdb': {'train': imdb_train, 'valid': imdb_valid, 'test': imdb_test}\n",
    "}\n",
    "\n",
    "# Group sets\n",
    "training = {'yelp': yelp_train, 'imdb': imdb_train}\n",
    "valid = {'yelp': yelp_valid, 'imdb': imdb_valid}\n",
    "test = {'yelp': yelp_test, 'imdb': imdb_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK DATA:\n",
      "YELP size: 7000\n",
      "                                              Review  Label\n",
      "0  I can't believe I haven't yelped about the pla...      5\n",
      "1  Best nights to go to Postino's are Mondays and...      5\n",
      "2  Went here tonight with the padres and husband....      5\n",
      "3  I must be spoiled and realize that this is not...      3\n",
      "4  Normally, love this store & have been a member...      2 \n",
      " --------------------------------------------------------------------------------\n",
      "IMDB size: 15000\n",
      "                                              Review  Label\n",
      "0  For a movie that gets no respect there sure ar...      1\n",
      "1  Bizarre horror movie filled with famous faces ...      1\n",
      "2  A solid, if unremarkable film. Matthau, as Ein...      1\n",
      "3  It's a strange feeling to sit alone in a theat...      1\n",
      "4  You probably all already know this by now, but...      1 \n",
      " --------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check\n",
    "print('CHECK DATA:')\n",
    "for name, training_set in training.items():\n",
    "    print(name.upper(), 'size:', str(len(training_set)))\n",
    "    print(training_set.head(), '\\n', '-' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Convert both datasets in binary and frequency BoW\n",
    "\n",
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER PREPROCESSING:\n",
      "                                              Review  Label\n",
      "0  i cant believe i havent yelped about the place...      5\n",
      "1  best nights to go to postinos are mondays and ...      5\n",
      "2  went here tonight with the padres and husband ...      5\n",
      "3  i must be spoiled and realize that this is not...      3\n",
      "4  normally love this store  have been a member f...      2 \n",
      " --------------------------------------------------------------------------------\n",
      "                                              Review  Label\n",
      "0  for a movie that gets no respect there sure ar...      1\n",
      "1  bizarre horror movie filled with famous faces ...      1\n",
      "2  a solid if unremarkable film matthau as einste...      1\n",
      "3  its a strange feeling to sit alone in a theate...      1\n",
      "4  you probably all already know this by now but ...      1 \n",
      " --------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for s in datasets.values():\n",
    "    for df in s.values():\n",
    "        preprocess(df, 'Review')\n",
    "\n",
    "# Verify preprocessing\n",
    "print('\\nAFTER PREPROCESSING:')\n",
    "for name, training_set in training.items():\n",
    "    print(training_set.head(), '\\n', '-' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate vocabulary for yelp and imdb datasets from training data, and write to file\n",
    "vocabulary = get_vocabulary(training, 'Review', M_FEATURES, WRITE)\n",
    "\n",
    "# Write converted datasets to file\n",
    "if WRITE:\n",
    "    write_converted_dataset(datasets, vocabulary, 'yelp')\n",
    "    write_converted_dataset(datasets, vocabulary, 'imdb')\n",
    "    \n",
    "# Shuffle data\n",
    "for s in datasets.values():\n",
    "    for key in s:\n",
    "        s[key] = s[key].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Bag of words. _binary is for binary BoW. _freq is for frequency BoW\n",
    "yelp_binary, yelp_freq = bag_of_words(datasets['yelp'], vocabulary['yelp'])\n",
    "imdb_binary, imdb_freq = bag_of_words(datasets['imdb'], vocabulary['imdb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Yelp Binary BoW f1 scores on random uniform classifier, majority-class classifier, Naive Bayes, Decision Trees, LinearSVM w/ hyperparameter tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yelp Binary Bag of Words Performances\n",
      "\tScores using RANDOM_CLASSIFIER:\n",
      "\t\tTRAIN: 0.20385714285714285\n",
      "\t\tVALID: 0.20999999999999996\n",
      "\t\tTEST: 0.197\n",
      "\tScores using MAJORITY_CLASS_CLASSIFIER:\n",
      "\t\tTRAIN: 0.3525714285714286\n",
      "\t\tVALID: 0.356\n",
      "\t\tTEST: 0.351\n"
     ]
    }
   ],
   "source": [
    "print('Yelp Binary Bag of Words Performances')\n",
    "do_clf_test(random_classifier, yelp_binary) # Random uniform classifier\n",
    "do_clf_test(majority_class_classifier, yelp_binary) # Majority class classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScores using BERNOULLINB:\n",
      "\t\tBest params: {'alpha': 0.02}\n",
      "\t\tTRAIN: 0.7281428571428571\n",
      "\t\tVALID: 0.672\n",
      "\t\tTEST: 0.4355\n"
     ]
    }
   ],
   "source": [
    "# BernoulliNB\n",
    "params = {'alpha': np.arange(0.01, 1.01, 0.01)}\n",
    "do_clf_test(BernoulliNB(), yelp_binary, params, tune=PERFORM_TUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScores using DECISIONTREECLASSIFIER:\n",
      "\t\tBest params: {'max_depth': 16, 'max_features': 0.30000000000000004, 'min_samples_leaf': 5}\n",
      "\t\tTRAIN: 0.5712857142857143\n",
      "\t\tVALID: 0.594\n",
      "\t\tTEST: 0.376\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "params = {'max_depth': np.arange(13, 17),\n",
    "          'max_features': np.arange(0.1, 0.5, 0.1),\n",
    "          'min_samples_leaf': np.arange(3, 6)}\n",
    "do_clf_test(DecisionTreeClassifier(), yelp_binary, params, tune=PERFORM_TUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScores using LINEARSVC:\n",
      "\t\tBest params: {'C': 0.01, 'max_iter': 10}\n",
      "\t\tTRAIN: 0.8327142857142857\n",
      "\t\tVALID: 0.827\n",
      "\t\tTEST: 0.5085\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM\n",
    "params = {'C': np.logspace(-2, 2, num=8),\n",
    "          'max_iter': np.arange(10, 100, 10)}\n",
    "do_clf_test(LinearSVC(), yelp_binary, params, tune=PERFORM_TUNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Yelp Frequency BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yelp Frequency Bag of Words Performances\n",
      "\tScores using RANDOM_CLASSIFIER:\n",
      "\t\tTRAIN: 0.20257142857142857\n",
      "\t\tVALID: 0.193\n",
      "\t\tTEST: 0.191\n",
      "\tScores using MAJORITY_CLASS_CLASSIFIER:\n",
      "\t\tTRAIN: 0.3525714285714286\n",
      "\t\tVALID: 0.356\n",
      "\t\tTEST: 0.351\n"
     ]
    }
   ],
   "source": [
    "print('Yelp Frequency Bag of Words Performances')\n",
    "do_clf_test(random_classifier, yelp_freq)\n",
    "do_clf_test(majority_class_classifier, yelp_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScores using GAUSSIANNB:\n",
      "\t\tTRAIN: 0.747\n",
      "\t\tVALID: 0.278\n",
      "\t\tTEST: 0.284\n"
     ]
    }
   ],
   "source": [
    "# GaussianNB: Requires dense arrays\n",
    "do_clf_test(GaussianNB(), {key: [value[0].toarray(), value[1]] for key, value in yelp_freq.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScores using DECISIONTREECLASSIFIER:\n",
      "\t\tBest params: {'max_depth': 13, 'max_features': 0.1, 'min_samples_leaf': 4}\n",
      "\t\tTRAIN: 0.549\n",
      "\t\tVALID: 0.519\n",
      "\t\tTEST: 0.38649999999999995\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "params = {'max_depth': np.arange(13, 17),\n",
    "          'max_features': np.arange(0.1, 0.5, 0.1),\n",
    "          'min_samples_leaf': np.arange(3, 6)}\n",
    "do_clf_test(DecisionTreeClassifier(), yelp_freq, params, tune=PERFORM_TUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScores using LINEARSVC:\n",
      "\t\tBest params: {'C': 0.517947467923121, 'max_iter': 20}\n",
      "\t\tTRAIN: 0.7477142857142857\n",
      "\t\tVALID: 0.752\n",
      "\t\tTEST: 0.5345\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM\n",
    "params = {'C': np.logspace(-2, 2, num=8),\n",
    "          'max_iter': np.arange(10, 100, 10)}\n",
    "do_clf_test(LinearSVC(), yelp_freq, params, tune=PERFORM_TUNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Repeat Q2 and Q3 with IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB Binary Bag of Words Performances\n",
      "\tScores using RANDOM_CLASSIFIER:\n",
      "\t\tTRAIN: 0.497\n",
      "\t\tVALID: 0.4997\n",
      "\t\tTEST: 0.49744\n"
     ]
    }
   ],
   "source": [
    "print('IMDB Binary Bag of Words Performances')\n",
    "do_clf_test(random_classifier, imdb_binary)\n",
    "# Majority class classifier doesn't make sense for IMDB since it is a balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScores using BERNOULLINB:\n",
      "\t\tBest params: {'alpha': 0.11}\n",
      "\t\tTRAIN: 0.8692\n",
      "\t\tVALID: 0.8668\n",
      "\t\tTEST: 0.84036\n"
     ]
    }
   ],
   "source": [
    "# BernoulliNB\n",
    "params = {'alpha': np.arange(0.01, 1.01, 0.01)}\n",
    "do_clf_test(BernoulliNB(), imdb_binary, params, tune=PERFORM_TUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScores using DECISIONTREECLASSIFIER:\n",
      "\t\tBest params: {'max_depth': 16, 'max_features': 0.4, 'min_samples_leaf': 3}\n",
      "\t\tTRAIN: 0.8032\n",
      "\t\tVALID: 0.8105\n",
      "\t\tTEST: 0.7314\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "params = {'max_depth': np.arange(13, 17),\n",
    "          'max_features': np.arange(0.1, 0.5, 0.1),\n",
    "          'min_samples_leaf': np.arange(3, 6)}\n",
    "do_clf_test(DecisionTreeClassifier(), imdb_binary, params, tune=PERFORM_TUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScores using LINEARSVC:\n",
      "\t\tBest params: {'C': 0.01, 'max_iter': 10}\n",
      "\t\tTRAIN: 0.9538666666666666\n",
      "\t\tVALID: 0.9523\n",
      "\t\tTEST: 0.87952\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM\n",
    "params = {'C': np.logspace(-2, 2, num=8),\n",
    "          'max_iter': np.arange(10, 100, 10)}\n",
    "do_clf_test(LinearSVC(), imdb_binary, params, tune=PERFORM_TUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB Frequency Bag of Words Performances\n",
      "\tScores using RANDOM_CLASSIFIER:\n",
      "\t\tTRAIN: 0.5029333333333333\n",
      "\t\tVALID: 0.4964\n",
      "\t\tTEST: 0.50316\n"
     ]
    }
   ],
   "source": [
    "print('IMDB Frequency Bag of Words Performances')\n",
    "do_clf_test(random_classifier, imdb_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScores using GAUSSIANNB:\n",
      "\t\tTRAIN: 0.8693333333333333\n",
      "\t\tVALID: 0.7673\n",
      "\t\tTEST: 0.70544\n"
     ]
    }
   ],
   "source": [
    "# GaussianNB: Requires dense arrays\n",
    "# No parameters to tune\n",
    "do_clf_test(GaussianNB(), {key: [value[0].toarray(), value[1]] for key, value in imdb_freq.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScores using DECISIONTREECLASSIFIER:\n",
      "\t\tBest params: {'max_depth': 14, 'max_features': 0.4, 'min_samples_leaf': 5}\n",
      "\t\tTRAIN: 0.7824666666666666\n",
      "\t\tVALID: 0.7844\n",
      "\t\tTEST: 0.71776\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "params = {'max_depth': np.arange(13, 17),\n",
    "          'max_features': np.arange(0.1, 0.5, 0.1),\n",
    "          'min_samples_leaf': np.arange(3, 6)}\n",
    "do_clf_test(DecisionTreeClassifier(), imdb_freq, params, tune=PERFORM_TUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScores using LINEARSVC:\n",
      "\t\tBest params: {'C': 1.9306977288832496, 'max_iter': 40}\n",
      "\t\tTRAIN: 0.9468666666666666\n",
      "\t\tVALID: 0.9421\n",
      "\t\tTEST: 0.88276\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM\n",
    "params = {'C': np.logspace(-2, 2, num=8),\n",
    "          'max_iter': np.arange(10, 100, 10)}\n",
    "do_clf_test(LinearSVC(), imdb_freq, params, tune=PERFORM_TUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp551",
   "language": "python",
   "name": "comp551"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
